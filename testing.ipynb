{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad9c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176c1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAS 접근방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b89e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_path = \"Z:\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "785d27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'clam_data', 'level0', 'level2', 'patch', 'practice', 'target_ln.csv', 'train', 'valid']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.path.join(nas_path, \"data\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c24565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image\n",
    "import random\n",
    "import openslide\n",
    "import re\n",
    "import math\n",
    "from skimage.morphology import skeletonize\n",
    "import xml.etree.ElementTree as ET\n",
    "import tifffile\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as trasnforms\n",
    "\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392a82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value) \n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\\n\n",
    "        torch.backends.cudnn.deterministic = True  #needed\\n\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "random_seed(seed,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a51bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "psize = (224,224)\n",
    "level_3 = 3\n",
    "level_1 = 1\n",
    "overlap = (192,192)\n",
    "batch_size = 100\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd0f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = {\n",
    "    'level_3' : \"Z:\\\\hsyoo\\\\pth\\\\pth_80\\\\level_3\\\\best_model_level3.pth\",\n",
    "    'level_1' : \"hi\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9136d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a04abf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imtrans = A.Compose([\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51ecb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wsi_clf(slide, level, psize, overlap, net):\n",
    "    max_x = slide.level_dimensions[level][0]\n",
    "    max_y = slide.level_dimensions[level][1]\n",
    "    num = 0\n",
    "    \n",
    "    \n",
    "    out_fill_3 = np.zeros(psize)\n",
    "    out_fill_2 = np.zeros((psize[0]//2,psize[1]//2))\n",
    "    out_fill_1 = np.zeros((psize[0]//4, psize[1]//4))\n",
    "    if level == 3 or level == 4:\n",
    "        overlay = np.zeros([max_y, max_x])\n",
    "        reference = np.zeros([max_y, max_x])\n",
    "    elif level == 2:\n",
    "        overlay = np.zeros([max_y//2, max_x//2])\n",
    "        reference = np.zeros([max_y//2, max_x//2])\n",
    "    elif level == 1:\n",
    "        overlay = np.zeros([max_y//4, max_x//4])\n",
    "        reference = np.zeros([max_y//4, max_x//4])\n",
    "\n",
    "    steps_x = int(math.ceil((max_x - overlap[0]) / float(psize[0] - overlap[0])))\n",
    "    steps_y = int(math.ceil((max_y - overlap[1]) / float(psize[1] - overlap[1])))\n",
    "    start_coords = list()\n",
    "    \n",
    "    for y in tqdm(range(0,steps_y)):\n",
    "        col_list = list()\n",
    "        \n",
    "        for x in range(0, steps_x):\n",
    "            x_start = x*(psize[0] - overlap[0])\n",
    "            x_end = x_start + psize[0]\n",
    "            y_start = y*(psize[1] - overlap[1])\n",
    "            y_end = y_start + psize[1]\n",
    "            \n",
    "            if (x_end > max_x):\n",
    "                x_overlap = x_end - max_x\n",
    "                x_start = max_x - psize[0]\n",
    "                x_end = max_x\n",
    "            if(y_end > max_y):\n",
    "                y_start = max_y - psize[1]\n",
    "                y_end = max_y\n",
    "                \n",
    "            temp = np.array(slide.read_region((x_start*(2**(level)), y_start*(2**(level))), level, psize))\n",
    "            temp = temp[:,:,:3]\n",
    "            temp = temp.astype(np.uint8)\n",
    "            temp = val_imtrans(image = temp)['image'].unsqueeze(0).to(device).float()\n",
    "\n",
    "            if level == 3 or level ==4:\n",
    "                start_coords.append((y_start,x_start))\n",
    "            elif level == 2:\n",
    "                start_coords.append((y_start//2,x_start//2))\n",
    "            elif level == 1:\n",
    "                start_coords.append((y_start//4,x_start//4))\n",
    "            \n",
    "            \"\"\"\n",
    "            batch size로 쌓기\n",
    "            \"\"\"\n",
    "            if num==0:\n",
    "                cat = temp\n",
    "            else:\n",
    "                cat = torch.cat((cat,temp), dim = 0)\n",
    "            num+=1\n",
    "            \n",
    "            \"\"\"\n",
    "            model에 배치로 넣기\n",
    "            \"\"\"\n",
    "            if num == batch_size:\n",
    "                out = net(cat)\n",
    "                out = F.softmax(out, dim = 1)\n",
    "                out = out.detach().cpu().numpy()\n",
    "                out = out[:,1]\n",
    "                if level == 3 or level == 4:\n",
    "                    for i in range(batch_size):\n",
    "                        out_fill_3.fill(out[i])\n",
    "                        overlay[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] += out_fill_3\n",
    "                        reference[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] +=1\n",
    "                        if i ==batch_size-1:\n",
    "                            num=0\n",
    "                            start_coords = []\n",
    "                elif level == 2:\n",
    "                    for i in range(batch_size):\n",
    "                        out_fill_2.fill(out[i])\n",
    "                        overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] += out_fill_2\n",
    "                        reference[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] +=1\n",
    "                        if i ==batch_size-1:\n",
    "                            num=0\n",
    "                            start_coords = []\n",
    "                elif level == 1:\n",
    "                    for i in range(batch_size):\n",
    "                        out_fill_1.fill(out[i])\n",
    "                        overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] += out_fill_1\n",
    "                        reference[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] +=1\n",
    "                        if i ==batch_size-1:\n",
    "                            num=0\n",
    "                            start_coords = []\n",
    "            elif y==steps_y-1 and x==steps_x-1:\n",
    "                out = net(cat)\n",
    "                out = F.softmax(out, dim = 1)\n",
    "                out = out.detach().cpu().numpy()\n",
    "                out = out[:,1]\n",
    "                if level == 3 or level == 4:\n",
    "                    for i in range(num):\n",
    "                        out_fill_3.fill(out[i])\n",
    "                        overlay[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] += out_fill_3\n",
    "                        reference[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] +=1\n",
    "                elif level ==2:\n",
    "                    for i in range(num):\n",
    "                        out_fill_2.fill(out[i])\n",
    "                        overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] += out_fill_2\n",
    "                        reference[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] +=1\n",
    "                elif level ==1:\n",
    "                    for i in range(num):\n",
    "                        out_fill_1.fill(out[i])\n",
    "                        overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] += out_fill_1\n",
    "                        reference[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] +=1\n",
    "\n",
    "    output = overlay / reference\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7d3ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained = True, num_classes = 2)\n",
    "net.load_state_dict(torch.load(model_path['level_3']))\n",
    "net = net.to(device).eval()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "root_dir = \"Z:\\\\data\\\\\"\n",
    "modes = [\"valid\"]\n",
    "meta_labels = [\"NOLN_metastasis\", \"LN_metastasis\"]\n",
    "wsi_fns = list()\n",
    "include_num = []\n",
    "for i in range(66,101):\n",
    "    num = format(i, '03')\n",
    "    include_num.append(num)\n",
    "for mode in modes:\n",
    "    for meta_label in meta_labels:\n",
    "        for patient in sorted(os.listdir(os.path.join(root_dir, mode, meta_label))):\n",
    "            if patient.split('.')[-1] == 'mrxs' and patient.split('.')[0].split('_')[1] in include_num:\n",
    "                wsi_fns.append(os.path.join(root_dir, mode, meta_label, patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "867baefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnifications_40x = [\"LN_068\", \"LN_069\", \"LN_070\", \"LN_071\", \"LN_072\", \"LN_073\", \"LN_074\", \"LN_075\", \"LN_076\", \"LN_077\", \n",
    "\"LN_078\", \"LN_079\", \"LN_080\", \"LN_081\", \"LN_082\", \"LN_083\", \"LN_084\", \"LN_085\", \"LN_086\", \"LN_087\", \n",
    "\"LN_088\", \"LN_089\", \"LN_090\", \"LN_091\", \"LN_092\", \"LN_093\", \"LN_094\", \"LN_095\", \"LN_096\", \"LN_097\",\n",
    "\"LN_098\",  \"LN_099\", \"LN_100\", \"NOLN_067\", \"NOLN_068\", \"NOLN_069\", \"NOLN_070\", \"NOLN_071\", \"NOLN_072\", \"NOLN_073\", \"NOLN_074\", \n",
    "\"NOLN_075\", \"NOLN_076\", \"NOLN_077\", \"NOLN_078\", \"NOLN_079\", \"NOLN_080\", \"NOLN_081\", \"NOLN_082\", \n",
    "\"NOLN_083\", \"NOLN_084\", \"NOLN_085\", \"NOLN_086\", \"NOLN_087\", \"NOLN_088\", \"NOLN_089\", \"NOLN_090\", \n",
    "\"NOLN_091\", \"NOLN_092\", \"NOLN_093\", \"NOLN_094\", \"NOLN_095\", \"NOLN_096\", \"NOLN_097\", \"NOLN_098\", \n",
    "\"NOLN_099\", \"NOLN_100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947be626",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wsi_fn in wsi_fns:\n",
    "    name = wsi_fn.split('/')[-1].split('.')[0]\n",
    "    print(name)\n",
    "    if name in magnifications_40x:\n",
    "        level_3 = 4\n",
    "    else:\n",
    "        level_3 = 3\n",
    "    \n",
    "#     f = h5py.File(f'/mnt/pathology/hsyoo/h5/heatmap/{name}.h5', 'w')\n",
    "    slide = openslide.OpenSlide(wsi_fn)\n",
    "    print(f\"slide.level_dimensions : {slide.level_dimensions}, apply level : {level_3}\")\n",
    "    overlay_3 = read_wsi_clf(slide, level_3, psize, overlap, net)\n",
    "    print(f\"overlay_3 shape : {overlay_3.shape}\")\n",
    "    print(f\"overlay_3 min max : {overlay_3.min()}, {overlay_3.max()}\")\n",
    "    f['level_3'] = overlay_3\n",
    "    \n",
    "    \"\"\"\n",
    "    여기 위에 overlay추가 가능, 밑부터는 저장단계\n",
    "    \"\"\"\n",
    "    d=copy.deepcopy(overlay_3)\n",
    "    overlay_3[overlay_3 >= threshold] =1\n",
    "    overlay_3[overlay_3 < threshold] = 0\n",
    "    overlay_3 = overlay_3.astype(bool)\n",
    "    b = morphology.remove_small_objects(overlay_3, 50000, connectivity=8)\n",
    "    c = morphology.remove_small_holes(b, 50000, connectivity=8)\n",
    "    slide = np.array(slide.read_region((0,0),level_3,slide.level_dimensions[level_3]))[:,:,:3]\n",
    "    \n",
    "    f['post'] = c # post-processing\n",
    "    \"\"\"\n",
    "    visualization\n",
    "    \"\"\"\n",
    "    fig = plt.figure(dpi = 200)\n",
    "    ax = fig.add_subplot(1,4,1)\n",
    "    plt.imshow(slide)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{name}\")\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1,4,2)\n",
    "    plt.imshow(slide)\n",
    "    plt.imshow(overlay_3,cmap='jet', alpha = 0.5)\n",
    "    plt.title('Prediction')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,3)\n",
    "    plt.imshow(slide)\n",
    "    plt.imshow(c,cmap='jet', alpha = 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title('Post-process')\n",
    "\n",
    "    ax = fig.add_subplot(1,4,4)\n",
    "    im = plt.imshow(d, vmin = 0.5, vmax = 1.0, cmap = 'jet')\n",
    "    plt.title('heatmap')\n",
    "    plt.axis('off')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im, cax=cax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#     fig.savefig(f\"/mnt/pathology/hsyoo/step1_predict/heatmap_80/{name}_l3.png\")\n",
    "    plt.close(fig)\n",
    "    \"\"\"\n",
    "    위까지는 저장단계, 밑부터는 후처리 단계! -> 후처리는 bool형태로 이루어져야하므로 Thresholding이 발생한다!\n",
    "    자세한 후처리 사항들은 check_segmentation_80의 remove_small_object, remove_small_holes를 통해 진행하자.\n",
    "    step2 aug짜는건 후처리 전 threshold값으로 미리 짜둘 수 있다. bool로 바꾸면 어차피 똑같\n",
    "    \"\"\"\n",
    "    # ~~~\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
