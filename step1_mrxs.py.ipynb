{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dba8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import skimage.transform\n",
    "import scipy.ndimage as nd\n",
    "import scipy.ndimage.morphology as mp\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser(description = \"step1 Cancer Segmentation EfficientNet-b0\")\n",
    "parser.add_argument('--batch_size', default = 100, type = int, help='batch size')\n",
    "parser.add_argument('--num_epochs', default = 50, type = int, help='training epochs')\n",
    "parser.add_argument('--lr', default = 0.02, type = float, help = 'learning rate')\n",
    "parser.add_argument('--num_workers', type = int, default = 6)\n",
    "parser.add_argument('--level', type = int, default = 1)\n",
    "parser.add_argument('--valid_s', type = int, default = 36)\n",
    "parser.add_argument('--valid_e', type = int, default = 41)\n",
    "parser.add_argument('--resume', default = False)\n",
    "parser.add_argument('--resume_epoch', type = int, default = 0)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "root_dir = '/mnt/hsyoo/data/patch/train'\n",
    "# batch_size = 100\n",
    "# learning_rate = 3e-4\n",
    "# num_epochs = 50\n",
    "# num_workers = 6\n",
    "# level = 3\n",
    "# valid_s = 36\n",
    "# valid_e = 41\n",
    "# resume = False\n",
    "# resume_epoch = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "seed = 42\n",
    "random_seed(seed, True)\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def path_list(root_dir, mode, valid_num, level):\n",
    "    data_list = []\n",
    "    num = 0\n",
    "    level_dim = str(level)\n",
    "    meta_labels = [\"NOLN_metastasis\", \"LN_metastasis\"]\n",
    "    cancer_labels = [\"normal\", \"cancer\"]\n",
    "    \n",
    "    for meta_label in sorted(os.listdir(os.path.join(root_dir))):\n",
    "        if meta_label not in meta_labels:\n",
    "            continue\n",
    "        for patient in sorted(os.listdir(os.path.join(root_dir, meta_label))):\n",
    "            if mode == 'train':\n",
    "                if 'LN' not in patient:\n",
    "                    continue\n",
    "                if patient.split('_')[-1] in valid_num:\n",
    "                    continue\n",
    "                else:\n",
    "                    for cancer_label in sorted(os.listdir(os.path.join(root_dir, meta_label, patient, level_dim))):\n",
    "                        if cancer_label not in cancer_labels:\n",
    "                            continue\n",
    "                        if cancer_label == 'normal':\n",
    "                            label_value = 0\n",
    "                        elif cancer_label == 'cancer':\n",
    "                            label_value = 1\n",
    "                        for image in sorted(os.listdir(os.path.join(root_dir, meta_label, patient, level_dim, cancer_label, \"img\"))):\n",
    "                            if image.split('.')[-1] != 'png':\n",
    "                                continue\n",
    "                            else:\n",
    "                                case = {\n",
    "                                    'image' : os.path.join(root_dir, meta_label, patient, level_dim, cancer_label, \"img\", image),\n",
    "                                    'label' : label_value\n",
    "                                }\n",
    "                                data_list.append(case)\n",
    "            else:\n",
    "                if patient.split('_')[-1] in valid_num:\n",
    "                    for cancer_label in sorted(os.listdir(os.path.join(root_dir, meta_label, patient, level_dim))):\n",
    "                        if cancer_label not in cancer_labels:\n",
    "                            continue\n",
    "                        if cancer_label == 'normal':\n",
    "                            label_value = 0\n",
    "                        elif cancer_label == 'cancer':\n",
    "                            label_value = 1\n",
    "                        for image in sorted(os.listdir(os.path.join(root_dir, meta_label, patient, level_dim, cancer_label, \"img\"))):\n",
    "                            if image.split('.')[-1] != 'png':\n",
    "                                continue\n",
    "                            else:\n",
    "                                case = {\n",
    "                                    'image' : os.path.join(root_dir, meta_label, patient, level_dim, cancer_label, \"img\", image),\n",
    "                                    'label' : label_value\n",
    "                                }\n",
    "                                data_list.append(case)\n",
    "    return data_list\n",
    "                            \n",
    "\n",
    "start = time.perf_counter()\n",
    "valid_num = list()\n",
    "for i in range(args.valid_s,args.valid_e):\n",
    "    val_num = format(i, '03')\n",
    "    valid_num.append(val_num)\n",
    "train_list = path_list(root_dir, \"train\", valid_num, args.level)\n",
    "valid_list = path_list(root_dir, \"valid\", valid_num, args.level)\n",
    "print(f\"training Level : {args.level}\")\n",
    "print('* Time: %.3f' %(time.perf_counter() - start))\n",
    "print(f\"train_list : {len(train_list)}, valid_list : {len(valid_list)}\")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path_list, transform = None):\n",
    "        self.path_list = path_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.path_list[index]['image'])\n",
    "        image = image.convert(\"RGB\")\n",
    "        label = torch.tensor(self.path_list[index]['label']).type(torch.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        data = {'image' : image, 'label' : label.item()}\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "\n",
    "tra = [\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "    transforms.RandomAffine((-10,10), shear=10, scale=(0.9, 1.2)),\n",
    "    transforms.RandomRotation(90),\n",
    "#     transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "val = [\n",
    "#     transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]\n",
    "\n",
    "trainset = MyDataset(train_list, transform = transforms.Compose(tra))\n",
    "validset = MyDataset(valid_list, transform = transforms.Compose(val))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size, shuffle = True, num_workers = args.num_workers, pin_memory = True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset,batch_size=args.batch_size, shuffle = False, num_workers = args.num_workers, pin_memory = True)\n",
    "\n",
    "\n",
    "net = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained = True, num_classes = 2)\n",
    "net = net.to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss() # loss\n",
    "alg = torch.optim.SGD(net.parameters(),lr=args.lr)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "if args.resume:\n",
    "    net.load_state_dict(torch.load(f'/mnt/hsyoo/pth/pth_80/level_{args.level}/eff_b0_pth_{args.resume_epoch - 1}.pth'))\n",
    "\n",
    "loss_train = np.array([])\n",
    "loss_valid = np.array([])\n",
    "accs_train = np.array([])\n",
    "accs_valid = np.array([])\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    stime = time.time()\n",
    "    net.train()\n",
    "    i=0\n",
    "    l_epoch = 0\n",
    "    correct = 0\n",
    "    l_epoch_val = 0\n",
    "    for item in tqdm(train_loader):\n",
    "        i=i+1\n",
    "        image, y = item['image'].to(device), item['label'].type(torch.long).to(device)\n",
    "        y_hat=net(image)\n",
    "        y_hat= F.softmax(y_hat, dim = 1)\n",
    "        l=loss(y_hat,y)\n",
    "        correct += (y_hat.argmax(dim=1)==y).sum()\n",
    "        l_epoch+=l\n",
    "        alg.zero_grad()\n",
    "        l.backward()\n",
    "        alg.step()\n",
    "    loss_train = np.append(loss_train,l_epoch.cpu().detach().numpy()/i)\n",
    "    accs_train = np.append(accs_train,correct.cpu()/np.float(len(trainset)))\n",
    "\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(valid_loader):\n",
    "            i +=1\n",
    "            image, y = item['image'].to(device), item['label'].to(device)\n",
    "            y_hat=net(image)\n",
    "            y_hat= F.softmax(y_hat, dim = 1)\n",
    "            l = loss(y_hat, y)\n",
    "            correct += (y_hat.argmax(dim=1)==y).sum()\n",
    "            l_epoch_val += l\n",
    "    accs_valid = np.append(accs_valid,correct.cpu()/np.float(len(validset)))\n",
    "    loss_valid = np.append(loss_valid, l_epoch_val.cpu().detach().numpy()/i)\n",
    "    if (correct.cpu()/np.float(len(validset))) > best_metric:\n",
    "        best_metric = correct.cpu()/np.float(len(validset))\n",
    "        best_metric_epoch = epoch\n",
    "        torch.save(net.state_dict(), f\"/mnt/hsyoo/pth/pth_80/level_{args.level}/best_model_level{args.level}.pth\")\n",
    "        print(\"saved new best metric model\")\n",
    "    \n",
    "#     torch.save(net.state_dict(), f'/nfs/paip2021/paip2021/data/pth/multi_clf_aug/level_{level}/eff_b0_pth_{epoch}.pth')\n",
    "    \n",
    "    if True:\n",
    "        fig = plt.figure(figsize = (12, 6))\n",
    "        ax = fig.add_subplot(1,2,1)\n",
    "        plt.plot(loss_train,label='train loss')\n",
    "        plt.plot(loss_valid, label='valid loss')\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.title('epoch: %d '%(epoch+1))\n",
    "\n",
    "        ax = fig.add_subplot(1,2,2)\n",
    "        plt.plot(accs_train,label='train accuracy')\n",
    "        plt.plot(accs_valid,label='valid accuracy')\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.pause(.0001)\n",
    "        plt.show()\n",
    "        fig.savefig(f\"/mnt/pathology/hsyoo/result/loss/loss_80/level_{args.level}/eff_b0_step1_cla_loss.png\")\n",
    "\n",
    "        print('train loss: ',loss_train[-1])\n",
    "        print('valid loss: ', loss_valid[-1])\n",
    "        print('train accuracy: ',accs_train[-1])\n",
    "        print('valid accuracy: ',accs_valid[-1])\n",
    "        print(f\"best metric epoch : {best_metric_epoch}, best metric accuracy : {best_metric}\")\n",
    "    print(f\"1 epoch time : {(time.time() - stime) / 60} min\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
