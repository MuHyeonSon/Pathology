{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c99cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openslide\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cb419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image\n",
    "import random\n",
    "import openslide\n",
    "import re\n",
    "import math\n",
    "from skimage.morphology import skeletonize\n",
    "import xml.etree.ElementTree as ET\n",
    "import tifffile\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as trasnforms\n",
    "\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnifications_40x = [\"LN_068\", \"LN_069\", \"LN_070\", \"LN_071\", \"LN_072\", \"LN_073\", \"LN_074\", \"LN_075\", \"LN_076\", \"LN_077\", \n",
    "\"LN_078\", \"LN_079\", \"LN_080\", \"LN_081\", \"LN_082\", \"LN_083\", \"LN_084\", \"LN_085\", \"LN_086\", \"LN_087\", \n",
    "\"LN_088\", \"LN_089\", \"LN_090\", \"LN_091\", \"LN_092\", \"LN_093\", \"LN_094\", \"LN_095\", \"LN_096\", \"LN_097\",\n",
    "\"LN_098\",  \"LN_099\", \"LN_100\", \"NOLN_067\", \"NOLN_068\", \"NOLN_069\", \"NOLN_070\", \"NOLN_071\", \"NOLN_072\", \"NOLN_073\", \"NOLN_074\", \n",
    "\"NOLN_075\", \"NOLN_076\", \"NOLN_077\", \"NOLN_078\", \"NOLN_079\", \"NOLN_080\", \"NOLN_081\", \"NOLN_082\", \n",
    "\"NOLN_083\", \"NOLN_084\", \"NOLN_085\", \"NOLN_086\", \"NOLN_087\", \"NOLN_088\", \"NOLN_089\", \"NOLN_090\", \n",
    "\"NOLN_091\", \"NOLN_092\", \"NOLN_093\", \"NOLN_094\", \"NOLN_095\", \"NOLN_096\", \"NOLN_097\", \"NOLN_098\", \n",
    "\"NOLN_099\", \"NOLN_100\", \"I_LN_001\", \"I_LN_002\", \"I_LN_003\", \"I_LN_004\", \n",
    "    \"I_LN_005\", \"I_LN_006\", \"I_LN_007\", \"I_LN_008\", \n",
    "    \"I_LN_009\", \"I_LN_010\", \"I_LN_011\", \"I_LN_012\", \"I_LN_013\",\n",
    "    \"I_LN_014\", \"I_LN_015\", \"I_LN_016\", \"I_LN_017\", \"I_LN_018\",\n",
    "    \"I_LN_019\", \"I_LN_020\", \"I_LN_021\", \"I_LN_022\", \"I_LN_023\",\n",
    "    \"I_LN_024\", \"I_LN_025\", \"I_LN_026\", \"I_LN_027\", \"I_LN_028\",\n",
    "    \"I_LN_029\", \"I_LN_030\",\n",
    "    \"I_NOLN_001\", \"I_NOLN_002\", \"I_NOLN_003\", \"I_NOLN_004\",\n",
    "    \"I_NOLN_005\", \"I_NOLN_006\", \"I_NOLN_007\", \"I_NOLN_008\", \n",
    "    \"I_NOLN_009\", \"I_NOLN_010\", \"I_NOLN_011\", \"I_NOLN_012\",\n",
    "    \"I_NOLN_013\", \"I_NOLN_014\", \"I_NOLN_015\", \"I_NOLN_016\",\n",
    "    \"I_NOLN_017\", \"I_NOLN_018\", \"I_NOLN_019\", \"I_NOLN_020\", \n",
    "    \"I_NOLN_021\", \"I_NOLN_022\", \"I_NOLN_023\", \"I_NOLN_024\", \n",
    "    \"I_NOLN_025\", \"I_NOLN_026\", \"I_NOLN_027\", \"I_NOLN_028\", \n",
    "    \"I_NOLN_029\", \"I_NOLN_030\", \"I_NOLN_031\", \"I_NOLN_032\", \n",
    "    \"I_NOLN_033\", \"I_NOLN_034\", \"I_NOLN_035\", \"I_NOLN_036\", \n",
    "    \"I_NOLN_037\", \"I_NOLN_038\", \"I_NOLN_039\", \"I_NOLN_040\", \n",
    "    \"I_NOLN_041\", \"I_NOLN_042\", \"I_NOLN_043\", \"I_NOLN_044\", \n",
    "    \"I_NOLN_045\", \"I_NOLN_046\", \"I_NOLN_047\", \"I_NOLN_048\", \n",
    "    \"I_NOLN_049\", \"I_NOLN_050\", \"I_NOLN_051\", \"I_NOLN_052\", \n",
    "    \"I_NOLN_053\", \"I_NOLN_054\", \"I_NOLN_055\", \"I_NOLN_056\", \n",
    "    \"I_NOLN_057\", \"I_NOLN_058\", \"I_NOLN_059\", \"I_NOLN_060\", \n",
    "    \"I_NOLN_061\", \"I_NOLN_062\", \"I_NOLN_063\", \"I_NOLN_064\", \n",
    "    \"I_NOLN_065\", \"I_NOLN_066\", \"I_NOLN_067\", \"I_NOLN_068\", \n",
    "    \"I_NOLN_069\", \"I_NOLN_070\", \"I_NOLN_071\", \"I_NOLN_072\", \n",
    "    \"I_NOLN_073\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16224bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value) \n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\\n\n",
    "        torch.backends.cudnn.deterministic = True  #needed\\n\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a213bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random_seed(seed,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "psize = (224,224)\n",
    "overlap_3 = (192,192)\n",
    "overlap_2 = (192,192)\n",
    "overlap_1 = (156,156)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = {\n",
    "    'level_3' : \"Y:\\\\hsyoo\\\\pth\\\\pth_80\\\\level_3\\\\best_model_level3.pth\",\n",
    "    'level_2' : \"Y:\\\\hsyoo\\\\pth\\\\pth_80\\\\level_2\\\\best_model_level2.pth\",\n",
    "    'level_1' : \"Y:\\\\hsyoo\\\\pth\\\\pth_80\\\\level_1\\\\best_model_level1.pth\"\n",
    "}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imtrans = A.Compose([\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66bfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wsi_clf(slide, level, psize, overlap, net, x40): # wsi읽고 classification\n",
    "    max_x = slide.level_dimensions[level][0]\n",
    "    max_y = slide.level_dimensions[level][1]\n",
    "    num = 0\n",
    "    \n",
    "    \n",
    "    out_fill_3 = np.zeros(psize)\n",
    "    out_fill_2 = np.zeros((psize[0]//2,psize[1]//2))\n",
    "    out_fill_1 = np.zeros((psize[0]//4, psize[1]//4))\n",
    "    if x40 == False:\n",
    "        if level == 3:\n",
    "            overlay = np.zeros([max_y, max_x])\n",
    "            reference = np.zeros([max_y, max_x])\n",
    "        elif level == 2:\n",
    "            overlay = np.zeros([max_y//2, max_x//2])\n",
    "            reference = np.zeros([max_y//2, max_x//2])\n",
    "        elif level == 1:\n",
    "            overlay = np.zeros([max_y//4, max_x//4])\n",
    "            reference = np.zeros([max_y//4, max_x//4])\n",
    "    elif x40 == True:\n",
    "        if level == 4:\n",
    "            overlay = np.zeros([max_y, max_x])\n",
    "            reference = np.zeros([max_y, max_x])\n",
    "        elif level == 3:\n",
    "            overlay = np.zeros([max_y//2, max_x//2])\n",
    "            reference = np.zeros([max_y//2, max_x//2])\n",
    "        elif level == 2:\n",
    "            overlay = np.zeros([max_y//4, max_x//4])\n",
    "            reference = np.zeros([max_y//4, max_x//4])\n",
    "\n",
    "    steps_x = int(math.ceil((max_x - overlap[0]) / float(psize[0] - overlap[0])))\n",
    "    steps_y = int(math.ceil((max_y - overlap[1]) / float(psize[1] - overlap[1])))\n",
    "    start_coords = list()\n",
    "    \n",
    "    for y in tqdm(range(0,steps_y)):\n",
    "        col_list = list()\n",
    "        \n",
    "        for x in range(0, steps_x):\n",
    "            x_start = x*(psize[0] - overlap[0])\n",
    "            x_end = x_start + psize[0]\n",
    "            y_start = y*(psize[1] - overlap[1])\n",
    "            y_end = y_start + psize[1]\n",
    "            \n",
    "            if (x_end > max_x):\n",
    "                x_overlap = x_end - max_x\n",
    "                x_start = max_x - psize[0]\n",
    "                x_end = max_x\n",
    "            if(y_end > max_y):\n",
    "                y_start = max_y - psize[1]\n",
    "                y_end = max_y\n",
    "                \n",
    "            temp = np.array(slide.read_region((x_start*(2**(level)), y_start*(2**(level))), level, psize))#*************\n",
    "            temp = temp[:,:,:3]\n",
    "            temp = temp.astype(np.uint8)\n",
    "            temp = val_imtrans(image = temp)['image'].unsqueeze(0).to(device).float() #스퀴즈(Squeeze) - 1인 차원을 제거한다.\n",
    "            # ex) 어떤 텐서가 (3 × 1)의 크기를 가집니다. 두번째 차원이 1이므로 squeeze를 사용하면 (3,)의 크기를 가지는 텐서로 변경됩니다.\n",
    "            \n",
    "            if x40 == False:\n",
    "                if level == 3:\n",
    "                    start_coords.append((y_start,x_start))\n",
    "                elif level == 2:\n",
    "                    start_coords.append((y_start//2,x_start//2))\n",
    "                elif level == 1:\n",
    "                    start_coords.append((y_start//4,x_start//4))\n",
    "            elif x40 == True:\n",
    "                if level == 4:\n",
    "                    start_coords.append((y_start,x_start))\n",
    "                elif level == 3:\n",
    "                    start_coords.append((y_start//2,x_start//2))\n",
    "                elif level == 2:\n",
    "                    start_coords.append((y_start//4,x_start//4))\n",
    "            \n",
    "            \"\"\"\n",
    "            batch size로 쌓기\n",
    "            \"\"\"\n",
    "            if num==0:\n",
    "                cat = temp\n",
    "            else:\n",
    "                cat = torch.cat((cat,temp), dim = 0)\n",
    "            num+=1\n",
    "            \n",
    "            \"\"\"\n",
    "            model에 배치로 넣기\n",
    "            \"\"\"\n",
    "            if num == batch_size:\n",
    "                out = net(cat)\n",
    "                out = F.softmax(out, dim = 1)\n",
    "                out = out.detach().cpu().numpy()\n",
    "                out = out[:,1]\n",
    "                if x40 == False:\n",
    "                    if level == 3:\n",
    "                        for i in range(batch_size):\n",
    "                            out_fill_3.fill(out[i]) #우선 np.zeros로 만들어 놓은 것 모델 출력 값으로 채움??\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] += out_fill_3\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] +=1\n",
    "                            if i ==batch_size-1:\n",
    "                                num=0\n",
    "                                start_coords = []\n",
    "                    elif level == 2:\n",
    "                        for i in range(batch_size):\n",
    "                            out_fill_2.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] += out_fill_2\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] +=1\n",
    "                            if i ==batch_size-1:\n",
    "                                num=0\n",
    "                                start_coords = []\n",
    "                    elif level == 1:\n",
    "                        for i in range(batch_size):\n",
    "                            out_fill_1.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] += out_fill_1\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] +=1\n",
    "                            if i ==batch_size-1:\n",
    "                                num=0\n",
    "                                start_coords = []\n",
    "                elif x40 == True:\n",
    "                    if level == 4:\n",
    "                        for i in range(batch_size):\n",
    "                            out_fill_3.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] += out_fill_3\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] +=1\n",
    "                            if i ==batch_size-1:\n",
    "                                num=0\n",
    "                                start_coords = []\n",
    "                    elif level == 3:\n",
    "                        for i in range(batch_size):\n",
    "                            out_fill_2.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] += out_fill_2\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] +=1\n",
    "                            if i ==batch_size-1:\n",
    "                                num=0\n",
    "                                start_coords = []\n",
    "                    elif level == 2:\n",
    "                        for i in range(batch_size):\n",
    "                            out_fill_1.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] += out_fill_1\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] +=1\n",
    "                            if i ==batch_size-1:\n",
    "                                num=0\n",
    "                                start_coords = []\n",
    "            elif y==steps_y-1 and x==steps_x-1:\n",
    "                out = net(cat)\n",
    "                out = F.softmax(out, dim = 1)\n",
    "                out = out.detach().cpu().numpy()\n",
    "                out = out[:,1]\n",
    "                if x40 == False:\n",
    "                    if level == 3:\n",
    "                        for i in range(num):\n",
    "                            out_fill_3.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] += out_fill_3\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] +=1\n",
    "                    elif level ==2:\n",
    "                        for i in range(num):\n",
    "                            out_fill_2.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] += out_fill_2\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] +=1\n",
    "                    elif level ==1:\n",
    "                        for i in range(num):\n",
    "                            out_fill_1.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] += out_fill_1\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] +=1\n",
    "                elif x40 == True:\n",
    "                    if level == 4:\n",
    "                        for i in range(num):\n",
    "                            out_fill_3.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] += out_fill_3\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0], start_coords[i][1]:start_coords[i][1]+psize[1]] +=1\n",
    "                    elif level ==3:\n",
    "                        for i in range(num):\n",
    "                            out_fill_2.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] += out_fill_2\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//2, start_coords[i][1]:start_coords[i][1]+psize[1]//2] +=1\n",
    "                    elif level ==2:\n",
    "                        for i in range(num):\n",
    "                            out_fill_1.fill(out[i])\n",
    "                            overlay[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] += out_fill_1\n",
    "                            reference[start_coords[i][0]:start_coords[i][0]+psize[0]//4, start_coords[i][1]:start_coords[i][1]+psize[1]//4] +=1\n",
    "    output = overlay / reference # overlay 가 무엇인지, reference 가 무엇인지\n",
    "    print(\"overlay\")\n",
    "    print(overlay)\n",
    "    print(\"\\n\")\n",
    "    print(\"reference\")\n",
    "    print(reference)\n",
    "    print(\"\\n\")\n",
    "    print(\"output\")\n",
    "    print(output)\n",
    "    print(\"\\n\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_white_image(png_save_dir, img, overlay, alpha):\n",
    "    overlay[overlay >= 0.9] = 255\n",
    "    overlay[overlay < 0.9] = 0\n",
    "    overlay = overlay[:,:,np.newaxis]\n",
    "    overlay = overlay.astype(np.uint8)\n",
    "    blended = img * alpha + overlay * (1-alpha)\n",
    "    blended = blended.astype(np.uint8)\n",
    "    blended = Image.fromarray(blended)\n",
    "    blended.save(os.path.join(png_save_dir, f\"white\\\\{name}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ca875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wsi_fns\")\n",
    "print(wsi_fns)\n",
    "print('\\n')\n",
    "print(\"wsi_fns_iv\")\n",
    "print(wsi_fns_iv)\n",
    "print('\\n')\n",
    "print(\"wsi_fns.extend(wsi_fns_iv)\")\n",
    "wsi_fns.extend(wsi_fns_iv)\n",
    "print(wsi_fns)\n",
    "print('\\n')\n",
    "\n",
    "print(f'wsi_fns_length:{length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfe39a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 위 코드 테스트 및 수정\n",
    "\n",
    "\n",
    "wsi_fns = list()\n",
    "wsi_fns_iv = []\n",
    "root_dir = \"Y:\\\\data\\\\clam_data\"\n",
    "for patient in sorted(os.listdir(root_dir)):\n",
    "    print(patient)\n",
    "    if patient.split('.')[-1] == 'mrxs':\n",
    "        print(os.path.join(root_dir, \"data\\\\clam_data\", patient))\n",
    "        wsi_fns.append(os.path.join(root_dir, patient))\n",
    "for patient in sorted(os.listdir(\"Y:\\\\VALIDATION\")):\n",
    "    if patient.split('.')[-1] == 'mrxs':\n",
    "        wsi_fns_iv.append(os.path.join(\"Y:\\\\VALIDATION\", patient))\n",
    "\n",
    "print(\"wsi_fns\")\n",
    "print(wsi_fns)\n",
    "print('\\n')\n",
    "print(\"wsi_fns_iv\")\n",
    "print(wsi_fns_iv)\n",
    "print('\\n')\n",
    "print(\"wsi_fns.extend(wsi_fns_iv)\")\n",
    "wsi_fns.extend(wsi_fns_iv)\n",
    "print(wsi_fns)\n",
    "print('\\n')\n",
    "\n",
    "net_3 = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained = True, num_classes = 2)\n",
    "net_3.load_state_dict(torch.load(model_path['level_3']))\n",
    "net_3 = net_3.to(device).eval()\n",
    "\n",
    "net_2 = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained = True, num_classes = 2)\n",
    "net_2.load_state_dict(torch.load(model_path['level_2']))\n",
    "net_2 = net_2.to(device).eval()\n",
    "\n",
    "net_1 = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained = True, num_classes = 2)\n",
    "net_1.load_state_dict(torch.load(model_path['level_1']))\n",
    "net_1 = net_1.to(device).eval()\n",
    "\n",
    "length = len(wsi_fns)\n",
    "print(f'wsi_fns_length:{length}')\n",
    "\n",
    "for idx, wsi_fn in enumerate(wsi_fns[104:length//2]):\n",
    "    print(\"0000000000\")\n",
    "    print(wsi_fn)\n",
    "    print(\"0000000000\")\n",
    "    name = wsi_fn.split(\"\\\\\")[-1].split('.')[0]\n",
    "    print(f\"idx : {idx}, slide name : {name}\")\n",
    "    slide = openslide.OpenSlide(wsi_fn)\n",
    "\n",
    "    if name in magnifications_40x:\n",
    "        level_3 = 4\n",
    "        level_2 = 3\n",
    "        level_1 = 2\n",
    "        x40 = True\n",
    "    elif name not in magnifications_40x:\n",
    "        level_3 = 3\n",
    "        level_2 = 2\n",
    "        level_1 = 1\n",
    "        x40 = False\n",
    "\n",
    "    if wsi_fn.split('\\\\')[2] == 'VALIDATION':\n",
    "        mask_save_dir = \"Y:\\\\mhson\\\\h5\\\\internal_valid\\\\ensemble\"\n",
    "        png_save_dir = \"Y:\\\\mhson\\\\cancer_ensemble\\\\internal_valid\"\n",
    "    else:\n",
    "        mask_save_dir = \"Y:\\\\mhson\\\\h5\\\\train\\\\ensemble\"\n",
    "        png_save_dir = \"Y:\\\\mhson\\\\cancer_ensemble\\\\train\"\n",
    "\n",
    "    img = np.array(slide.read_region((0,0), level_3, slide.level_dimensions[level_3]))[:,:,:3] #******************\n",
    "    f = h5py.File(os.path.join(mask_save_dir, f\"{name}.h5\"), 'w')\n",
    "    overlay_3 = read_wsi_clf(slide, level_3, psize, overlap_3, net_3, x40) #x40은 왜 주는건지 #read_wsi_clf의 출력 값은 원소값이 확률 값으로 이루어진 각 패치들이 담긴 리스트 ??\n",
    "    f['level_3'] = overlay_3\n",
    "    overlay_2 = read_wsi_clf(slide, level_2, psize, overlap_2, net_2, x40) #x40은 왜 주는건지\n",
    "    f['level_2'] = overlay_2\n",
    "    overlay_1 = read_wsi_clf(slide, level_1, psize, overlap_1, net_1, x40)\n",
    "    f['level_1'] = overlay_1\n",
    "    overlay = (overlay_3 + overlay_2 + overlay_1) / 3\n",
    "    f['ensemble'] = overlay\n",
    "    f.close()\n",
    "\n",
    "    fig = plt.figure(dpi = 200)\n",
    "    ax = fig.add_subplot(1,4,1)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(overlay_3, cmap = 'jet', alpha = 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"2.5X\") #25배\n",
    "\n",
    "    ax = fig.add_subplot(1,4,2)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(overlay_2, cmap = 'jet', alpha = 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"5X\") #50배\n",
    "\n",
    "    ax = fig.add_subplot(1,4,3)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(overlay_1, cmap = 'jet', alpha = 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"10X\") #100배\n",
    "\n",
    "    ax = fig.add_subplot(1,4,4)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(overlay, cmap = 'jet', alpha = 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ensemble\") #level1,2,3 다 더해서 3으로 나눈 것\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join(png_save_dir, f\"each\\\\{name}.png\"))\n",
    "    plt.close('all')\n",
    "    plt.close(fig)\n",
    "\n",
    "    make_white_image(png_save_dir, img, overlay, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f69556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8275a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
